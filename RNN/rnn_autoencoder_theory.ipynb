{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Autoencoder for Poetry: Theory Meets Practice\n",
    "\n",
    "**Educational Implementation with Mathematical Foundation**\n",
    "\n",
    "This notebook builds an RNN autoencoder for dimensionality reduction on poetry text, connecting deep theoretical insights with hands-on implementation. We follow the mathematical framework established in our theoretical exposition.\n",
    "\n",
    "## Theoretical Foundation Recap\n",
    "\n",
    "From our comprehensive analysis, we established that:\n",
    "\n",
    "1. **Dimensionality Reduction is Essential**: RNNs are practically unusable without reducing the effective dimension $d_{\\text{eff}} \\ll d$ where $d=300$ (GLoVe dimension)\n",
    "\n",
    "2. **Sample Complexity Improvement**: Joint input-output reduction improves complexity from $\\mathcal{O}(\\epsilon^{-600})$ to $\\mathcal{O}(\\epsilon^{-35})$ - exponential improvement\n",
    "\n",
    "3. **Autoencoder Optimality**: The encoder-bottleneck-decoder architecture is theoretically optimal for learning compressed representations\n",
    "\n",
    "4. **Poetry-Specific Challenges**: \n",
    "   - Sequence length $T=50$ requires careful gradient flow management\n",
    "   - Vocabulary size $V=1962$ creates high-dimensional discrete space\n",
    "   - Semantic structure in poetry may have lower intrinsic dimension\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "Input: [batch_size, seq_len, 300]  # GLoVe embeddings\n",
    "   ↓\n",
    "Encoder RNN: [batch_size, seq_len, hidden_dim] → [batch_size, bottleneck_dim]\n",
    "   ↓  \n",
    "Bottleneck: [batch_size, bottleneck_dim]  # Compressed representation (10-20D)\n",
    "   ↓\n",
    "Decoder RNN: [batch_size, bottleneck_dim] → [batch_size, seq_len, 300]\n",
    "   ↓\n",
    "Output: [batch_size, seq_len, 300]  # Reconstructed embeddings\n",
    "```\n",
    "\n",
    "**Key Design Decisions**:\n",
    "- **Bottleneck dimension**: 10-20D based on effective dimension analysis\n",
    "- **Hidden dimensions**: Start conservative (~64) to understand gradient flow\n",
    "- **Loss function**: MSE in embedding space (continuous, differentiable)\n",
    "- **Architecture**: Vanilla RNN first (educational), then LSTM if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Analysis\n",
    "\n",
    "Let's load our preprocessed poetry data and understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(314)\n",
    "torch.manual_seed(314)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "data_path = \"../GLoVe preprocessing/preprocessed_data/\"\n",
    "\n",
    "# Load metadata first to understand data structure\n",
    "with open(f\"{data_path}metadata_latest.json\", 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "    \n",
    "print(\"Data Structure:\")\n",
    "for key, value in metadata.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Load arrays\n",
    "embedding_sequences = np.load(f\"{data_path}embedding_sequences_latest.npy\")\n",
    "token_sequences = np.load(f\"{data_path}token_sequences_latest.npy\")\n",
    "attention_masks = np.load(f\"{data_path}attention_masks_latest.npy\")\n",
    "embedding_matrix = np.load(f\"{data_path}embedding_matrix_latest.npy\")\n",
    "\n",
    "print(f\"\\nActual shapes:\")\n",
    "print(f\"  Embedding sequences: {embedding_sequences.shape}  # (poems, seq_len, embedding_dim)\")\n",
    "print(f\"  Token sequences: {token_sequences.shape}        # (poems, seq_len)\")\n",
    "print(f\"  Attention masks: {attention_masks.shape}        # (poems, seq_len)\")\n",
    "print(f\"  Embedding matrix: {embedding_matrix.shape}      # (vocab_size, embedding_dim)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Interpretation**:\n",
    "- We have **128 poems** (some from 264 collection were filtered during preprocessing)\n",
    "- Each poem is **50 tokens** (padded/truncated)\n",
    "- **1962 vocabulary size** from our poetry corpus\n",
    "- **300D GLoVe embeddings** per token\n",
    "\n",
    "This gives us input tensors of shape `[128, 50, 300]` - exactly what our autoencoder expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first examine our data more closely and understand effective dimensionality\n",
    "print(\"=== Data Analysis for Architecture Design ===\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.FloatTensor(embedding_sequences)  # [128, 50, 300]\n",
    "attention_mask = torch.BoolTensor(attention_masks)  # [128, 50]\n",
    "\n",
    "print(f\"Input tensor shape: {X.shape}\")\n",
    "print(f\"Attention mask shape: {attention_mask.shape}\")\n",
    "\n",
    "# Analyze effective sequence lengths (before padding)\n",
    "real_lengths = attention_mask.sum(dim=1)  # Sum of True values per sequence\n",
    "print(f\"\\nSequence length statistics:\")\n",
    "print(f\"  Mean length: {real_lengths.float().mean():.1f}\")\n",
    "print(f\"  Min length: {real_lengths.min()}\")  \n",
    "print(f\"  Max length: {real_lengths.max()}\")\n",
    "print(f\"  Std length: {real_lengths.float().std():.1f}\")\n",
    "\n",
    "# Quick PCA to estimate effective dimensionality of embeddings\n",
    "# Flatten to [128*50, 300] for PCA, but only use non-padded tokens\n",
    "valid_embeddings = X[attention_mask]  # Get only non-padded embeddings\n",
    "print(f\"\\nValid embeddings for PCA: {valid_embeddings.shape}\")\n",
    "\n",
    "# Run PCA to understand intrinsic dimensionality\n",
    "pca = PCA(n_components=50)  # Look at first 50 components\n",
    "valid_embeddings_np = valid_embeddings.detach().numpy()\n",
    "pca_result = pca.fit_transform(valid_embeddings_np)\n",
    "\n",
    "# Plot explained variance\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "cumvar = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(cumvar[:30], 'b-', linewidth=2)\n",
    "plt.axhline(y=0.90, color='r', linestyle='--', alpha=0.7, label='90% variance')\n",
    "plt.axhline(y=0.95, color='orange', linestyle='--', alpha=0.7, label='95% variance')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA: Cumulative Explained Variance')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(pca.explained_variance_ratio_[:20], 'g-o', markersize=4)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA: Individual Component Variance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find effective dimensions\n",
    "dim_90 = np.where(cumvar >= 0.90)[0][0] + 1\n",
    "dim_95 = np.where(cumvar >= 0.95)[0][0] + 1\n",
    "print(f\"\\nEffective Dimensionality Analysis:\")\n",
    "print(f\"  Dimensions for 90% variance: {dim_90}\")\n",
    "print(f\"  Dimensions for 95% variance: {dim_95}\")\n",
    "print(f\"  This suggests bottleneck_dim ∈ [{dim_90-5}, {dim_95+5}] might work well\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
